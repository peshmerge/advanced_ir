{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02073693-b7b6-4050-8996-43af9733f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "import sys\n",
    "# from mapillary_sls.utils import eval\n",
    "from mapillary_sls.datasets.msls import MSLS\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1582b54-1b85-41b2-8504-f0f703b0e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/jovyan/FIR/mapillary_sls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d9d5cd1-d587-4113-abfb-918c16808046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(global_features,local_features):\n",
    "    \"\"\"when you apply just the sequeeze() it removes all the ones\n",
    "    #so (1,2048,1,1) after squeezing -> (2048), adding that extra dimension on the zero \n",
    "    #axis :- unsqueeze(0) (1,2048)\"\"\"\n",
    "    \n",
    "\n",
    "    if global_features.shape[0]==1:\n",
    "        # x = torch.cat([local_features,global_features],axis=1).squeeze().unsqueeze(0)\n",
    "        \n",
    "        x = np.multiply(local_features,global_features).squeeze().unsqueeze(0)\n",
    "\n",
    "    else: #if we have batch size!=1, then we dont have to unsqueeze because it wont squeeze the batch size       \n",
    "        # x = torch.cat([local_features,global_features],axis=1).squeeze()\n",
    "        \n",
    "        #hardaman product\n",
    "        x = np.multiply(local_features,global_features).squeeze()\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4852fb5d-924f-4253-9531-6a6099a155c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_matrix = torch.randn(1,2048)\n",
    "local_matrix = torch.randn(1,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a997413-f428-44c3-a420-6091cdb99e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(global_matrix,local_matrix).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77a191ed-0ba6-4d6e-bc39-fc67b86fd357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace46cbe-a281-45f6-8de0-126a7783d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= fusion(global_matrix,local_matrix)\n",
    "b= fusion(global_matrix,local_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b994fd37-4b27-44d2-9418-28841201da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FIR/advanced_ir/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dbe625-efc3-45e3-9ef1-b56b3334f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_distances(b,a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635a510-5e9d-4d28-81e1-fcdc3b8b7e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdbaaf4-256e-4ca0-810c-f67b39898ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17e404fa-073b-4351-9d43-a04a166dae79",
   "metadata": {},
   "source": [
    "first CPH length: 6595 second\n",
    "SF length: 4525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f609e582-f8ca-4034-86fa-aae750206b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(local_features_cph_query,global_features_cph_query,\n",
    "         local_features_sf_query,global_features_sf_query,\n",
    "         local_features_cph_database,global_features_cph_database,\n",
    "         local_features_sf_database,global_features_sf_database,df):\n",
    "    \n",
    "    CPH_LEN = 6595\n",
    "    SF_LEN = 4525\n",
    "    for row in range(df.shape[0]):    \n",
    "\n",
    "        if row<CPH_LEN:\n",
    "            #unsqueezing because when we access it we result in ([2048]), to make it ([1,2048])\n",
    "            #same for global\n",
    "            local_feature_query = local_features_cph_query[row].unsqueeze(0)\n",
    "            global_feature_query = global_features_cph_query[row].unsqueeze(0)\n",
    "            \n",
    "            #applying the fusion (1,4096)\n",
    "            query_fusion = fusion(global_feature_query,local_feature_query)\n",
    "            #eval basically converts to the required datatype given the string format\n",
    "\n",
    "            retrieved_indices = eval(df.iloc[row][\"retrieved_indicies\"])\n",
    "            retrieved_ids =  eval(df.iloc[row][\"retrieved_ids\"])\n",
    "            \n",
    "            idx_id = {i:j for i,j in zip(retrieved_indices,retrieved_ids)}\n",
    "     \n",
    "            database_feature_list = None\n",
    "            #fetching all the features first and concatenating them\n",
    "            for database_id in retrieved_indices:\n",
    "                #same reason as above(to why we unsqueezing)\n",
    "                global_feature_database = global_features_cph_database[database_id].unsqueeze(0)\n",
    "                \n",
    "                local_feature_database = local_features_cph_database[database_id].unsqueeze(0)\n",
    "                #(1,4096)\n",
    "                combined_features = fusion(global_feature_database,local_feature_database)\n",
    "                if database_feature_list is None:\n",
    "                    database_feature_list = combined_features\n",
    "                else:\n",
    "                    database_feature_list = torch.cat([database_feature_list,combined_features])\n",
    "            #so now we result the size of database_feature_list as -> (top_k,4096)\n",
    "            #computing the similarity so we get (1,top_k) size. 1 because, 1 query image passed in\n",
    "            similarity = cosine_similarity(query_fusion,database_feature_list)\n",
    "            # similarity =  manhattan_distances(query_fusion,database_feature_list)\n",
    "            #getting the indices of the most similar and mapping to the retrieved list\n",
    "            ranked_indices = [retrieved_indices[i] for i in np.argsort(similarity)[0]]\n",
    "\n",
    "            retrieved_file_names = [idx_id[i] for i in ranked_indices]\n",
    "\n",
    "            df.loc[row,\"re_ranked\"] = str(ranked_indices)\n",
    "            df.loc[row,\"re_ranked_ids\"] = str(retrieved_file_names)\n",
    "\n",
    "        else: #For SF\n",
    "            \n",
    "            row = abs(row-CPH_LEN) \n",
    "            \n",
    "            local_feature_query = local_features_sf_query[row].unsqueeze(0)\n",
    "            global_feature_query = global_features_sf_query[row].unsqueeze(0)\n",
    "\n",
    "            query_fusion = fusion(global_feature_query,local_feature_query)\n",
    "        \n",
    "            retrieved_indices = eval(df.iloc[CPH_LEN+row][\"retrieved_indicies\"])\n",
    "            \n",
    "            retrieved_ids =  eval(df.iloc[CPH_LEN+row][\"retrieved_ids\"])\n",
    "            \n",
    "            idx_id = {i:j for i,j in zip(retrieved_indices,retrieved_ids)}\n",
    "\n",
    "            \n",
    "            database_feature_list = None\n",
    "            \n",
    "            for database_id in retrieved_indices:\n",
    "          \n",
    "                global_feature_database = global_features_sf_database[database_id].unsqueeze(0)\n",
    "                \n",
    "                local_feature_database = local_features_sf_database[database_id].unsqueeze(0)\n",
    "                combined_features = fusion(global_feature_database,local_feature_database)\n",
    "                \n",
    "                if database_feature_list is None:\n",
    "                    database_feature_list = combined_features\n",
    "                else:\n",
    "                    database_feature_list = torch.cat([database_feature_list,combined_features])\n",
    "            \n",
    "            similarity = cosine_similarity(query_fusion,database_feature_list)\n",
    "            # similarity =  manhattan_distances(query_fusion,database_feature_list)\n",
    "            ranked_indices = [retrieved_indices[i] for i in np.argsort(similarity)[0]]\n",
    "            \n",
    "            retrieved_file_names = [idx_id[i] for i in ranked_indices]\n",
    "            \n",
    "            df.loc[CPH_LEN+row,\"re_ranked\"] = str(ranked_indices)\n",
    "            df.loc[CPH_LEN+row,\"re_ranked_ids\"] = str(retrieved_file_names)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7292d20c-6b1f-4d5c-b6d3-6f23a3a551a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"FIR\"\n",
    "DIR_ADVANCED_IR = os.path.join(DATA_ROOT, \"advanced_ir\") #i added the local features into a folder 'weights' in advanced_ir\n",
    "DATASET_ROOT = os.path.join(DATA_ROOT, \"msls\")\n",
    "DATASET_TEST = os.path.join(DATASET_ROOT, \"test\")\n",
    "DATASET_VAL = os.path.join(DATASET_ROOT, \"train_val\")\n",
    "DATASET_VAL_SF = os.path.join(DATASET_VAL, \"sf\")\n",
    "DATASET_VAL_CPH = os.path.join(DATASET_VAL, \"cph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5060eb-87a4-4641-919f-fbb93465cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4fcd9108-9986-4a70-8a05-7208121a3649",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_features_cph_query = torch.from_numpy(np.load(os.path.join(DIR_ADVANCED_IR,\"weights/MSLS_resnext_GCL_multi_attrous_attention_map_cph_local_queryfeats.npy\")))\n",
    "global_features_cph_query =  torch.from_numpy(np.load(os.path.join(DATA_ROOT,\"results/MSLS/val/MSLS_resnext_GeM_480_GCL_cph_queryfeats.npy\")))\n",
    "\n",
    "local_features_sf_query =  torch.from_numpy(np.load(os.path.join(DIR_ADVANCED_IR,\"weights/MSLS_resnext_GCL_multi_attrous_attention_map_sf_local_queryfeats.npy\")))\n",
    "global_features_sf_query =  torch.from_numpy(np.load(os.path.join(DATA_ROOT,\"results/MSLS/val/MSLS_resnext_GeM_480_GCL_sf_queryfeats.npy\")))\n",
    "\n",
    "local_features_cph_database =  torch.from_numpy(np.load(os.path.join(DIR_ADVANCED_IR,\"weights/MSLS_resnext_GCL_multi_attrous_attention_map_cph_local_mapfeats.npy\")))\n",
    "global_features_cph_database =  torch.from_numpy(np.load(os.path.join(DATA_ROOT,\"results/MSLS/val/MSLS_resnext_GeM_480_GCL_cph_mapfeats.npy\")))\n",
    "\n",
    "local_features_sf_database =  torch.from_numpy(np.load(os.path.join(DIR_ADVANCED_IR,\"weights/MSLS_resnext_GCL_multi_attrous_attention_map_sf_local_mapfeats.npy\")))\n",
    "global_features_sf_database =  torch.from_numpy(np.load(os.path.join(DATA_ROOT,\"results/MSLS/val/MSLS_resnext_GeM_480_GCL_sf_mapfeats.npy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6854716-e900-4934-bd35-79f5faa78aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #simulation \n",
    "\n",
    "\n",
    "# local_features_cph_query = torch.randn(6595,2048)\n",
    "# global_features_cph_query = torch.randn(6595,2048)\n",
    "\n",
    "# local_features_sf_query = torch.randn(4525,2048)\n",
    "# global_features_sf_query = torch.randn(4525,2048)\n",
    "\n",
    "# local_features_cph_database = torch.randn(20000,2048)\n",
    "# global_features_cph_database = torch.randn(20000,2048)\n",
    "\n",
    "# local_features_sf_database = torch.randn(20000,2048)\n",
    "# global_features_sf_database = torch.randn(20000,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dccb987-79b6-44b0-a2e5-711fd8c44efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(\"[1,2,3,4]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b49d9b7-e3de-429f-b8bd-7e75eb1b49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = rank(local_features_cph_query, global_features_cph_query,\n",
    "     local_features_sf_query,global_features_sf_query,\n",
    "     local_features_cph_database,global_features_cph_database,\n",
    "     local_features_sf_database,global_features_sf_database,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6218335f-2c0c-41d1-b3f4-03c3f6bdfe3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query_id</th>\n",
       "      <th>retrieved_ids</th>\n",
       "      <th>retrieved_indicies</th>\n",
       "      <th>re_ranked</th>\n",
       "      <th>re_ranked_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>x3vA7Bk0HNI6rGkDpDZQUQ</td>\n",
       "      <td>['X9V1oGRaAEFjq5jufrklTQ', 'E7gcrCyitkguCnMzoE...</td>\n",
       "      <td>[3, 5130, 5131, 0, 7912, 5132, 8812, 9186, 1, ...</td>\n",
       "      <td>[5130, 5131, 4505, 9182, 3, 4504, 1760, 8812, ...</td>\n",
       "      <td>['E7gcrCyitkguCnMzoEwm0Q', 'g4-eorh0MQsOO0el8w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>U9Vj0IV4q1psciXpj51F_w</td>\n",
       "      <td>['X9V1oGRaAEFjq5jufrklTQ', '22BOHMokEHyXf9LA8B...</td>\n",
       "      <td>[3, 4504, 1, 1815, 9186, 0, 2, 9181, 5131, 513...</td>\n",
       "      <td>[9184, 4504, 9183, 9181, 9182, 1, 1815, 4505, ...</td>\n",
       "      <td>['BAnIQgUKEjffD7QpwKr01g', '22BOHMokEHyXf9LA8B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Eh1NwQjH4jbKcWqVJ4ZsJg</td>\n",
       "      <td>['X9V1oGRaAEFjq5jufrklTQ', '_Eq8EgtwLGiMFc7VJd...</td>\n",
       "      <td>[3, 4, 2, 1815, 7604, 1, 0, 8810, 5, 9186, 6, ...</td>\n",
       "      <td>[3, 9181, 2, 8810, 1, 4504, 1815, 4, 9179, 918...</td>\n",
       "      <td>['X9V1oGRaAEFjq5jufrklTQ', '2LdC6tsHO7SnUEvyeH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1RKCGBAWsZbi5dj3vR2mlw</td>\n",
       "      <td>['_Eq8EgtwLGiMFc7VJdb-YQ', 'X9V1oGRaAEFjq5jufr...</td>\n",
       "      <td>[4, 3, 5, 6, 0, 8815, 9186, 9181, 8798, 1, 513...</td>\n",
       "      <td>[4, 9181, 3, 1, 9186, 8815, 0, 5, 8810, 4504, ...</td>\n",
       "      <td>['_Eq8EgtwLGiMFc7VJdb-YQ', '2LdC6tsHO7SnUEvyeH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LdiYwYkqgUfc1IYDu5ov9A</td>\n",
       "      <td>['Z4MR4AHQufgsCwiBiqQ23A', 'eQ-8kVNfMZiexVcu_V...</td>\n",
       "      <td>[5, 6, 4, 8815, 5133, 7049, 5125, 8816, 8811, ...</td>\n",
       "      <td>[4, 8815, 5, 8816, 12219, 34, 6, 5133, 3, 1225...</td>\n",
       "      <td>['_Eq8EgtwLGiMFc7VJdb-YQ', 'd_p1_335wiMgV_eu_3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                query_id  \\\n",
       "0           0  x3vA7Bk0HNI6rGkDpDZQUQ   \n",
       "1           1  U9Vj0IV4q1psciXpj51F_w   \n",
       "2           2  Eh1NwQjH4jbKcWqVJ4ZsJg   \n",
       "3           3  1RKCGBAWsZbi5dj3vR2mlw   \n",
       "4           4  LdiYwYkqgUfc1IYDu5ov9A   \n",
       "\n",
       "                                       retrieved_ids  \\\n",
       "0  ['X9V1oGRaAEFjq5jufrklTQ', 'E7gcrCyitkguCnMzoE...   \n",
       "1  ['X9V1oGRaAEFjq5jufrklTQ', '22BOHMokEHyXf9LA8B...   \n",
       "2  ['X9V1oGRaAEFjq5jufrklTQ', '_Eq8EgtwLGiMFc7VJd...   \n",
       "3  ['_Eq8EgtwLGiMFc7VJdb-YQ', 'X9V1oGRaAEFjq5jufr...   \n",
       "4  ['Z4MR4AHQufgsCwiBiqQ23A', 'eQ-8kVNfMZiexVcu_V...   \n",
       "\n",
       "                                  retrieved_indicies  \\\n",
       "0  [3, 5130, 5131, 0, 7912, 5132, 8812, 9186, 1, ...   \n",
       "1  [3, 4504, 1, 1815, 9186, 0, 2, 9181, 5131, 513...   \n",
       "2  [3, 4, 2, 1815, 7604, 1, 0, 8810, 5, 9186, 6, ...   \n",
       "3  [4, 3, 5, 6, 0, 8815, 9186, 9181, 8798, 1, 513...   \n",
       "4  [5, 6, 4, 8815, 5133, 7049, 5125, 8816, 8811, ...   \n",
       "\n",
       "                                           re_ranked  \\\n",
       "0  [5130, 5131, 4505, 9182, 3, 4504, 1760, 8812, ...   \n",
       "1  [9184, 4504, 9183, 9181, 9182, 1, 1815, 4505, ...   \n",
       "2  [3, 9181, 2, 8810, 1, 4504, 1815, 4, 9179, 918...   \n",
       "3  [4, 9181, 3, 1, 9186, 8815, 0, 5, 8810, 4504, ...   \n",
       "4  [4, 8815, 5, 8816, 12219, 34, 6, 5133, 3, 1225...   \n",
       "\n",
       "                                       re_ranked_ids  \n",
       "0  ['E7gcrCyitkguCnMzoEwm0Q', 'g4-eorh0MQsOO0el8w...  \n",
       "1  ['BAnIQgUKEjffD7QpwKr01g', '22BOHMokEHyXf9LA8B...  \n",
       "2  ['X9V1oGRaAEFjq5jufrklTQ', '2LdC6tsHO7SnUEvyeH...  \n",
       "3  ['_Eq8EgtwLGiMFc7VJdb-YQ', '2LdC6tsHO7SnUEvyeH...  \n",
       "4  ['_Eq8EgtwLGiMFc7VJdb-YQ', 'd_p1_335wiMgV_eu_3...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3559bf2a-5b4c-4002-b510-bb8afe9920d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['X9V1oGRaAEFjq5jufrklTQ', 'E7gcrCyitkguCnMzoEwm0Q', 'g4-eorh0MQsOO0el8wrQ0Q', 'm6_LAhWivjGN4O1fkWm6Gw', 'rNOc67N1lUpuQdDqMc9iUQ', '2iELaTjZQvTUOqi1G-uFUw', 'BvCML_i7yJ-IQirIbJj1_w', 'cijehvVtYCsUg8zIrH4boQ', 'HU9GEfLAB9pm5RmjW4MLhg', 'LGs_F4ALCGDWcVLAc1ym4g', 'b4DDF66_z7uy0NhR_yS12g', '_C1Fitf1GjOWGaNXb3C_7w', 'xp4LFHoCTNBUsUYeYCikAQ', '8hzxYYDBWYXIpfyJdJ-t7A', 'BgoGEom_0otCYWHjJ3jHEw', 'Lckc0FDH0Cfnm5cX6ooCCw', 'a2XfPwewrk0xSw-xfV5T1w', 'ni51v2-IoBjBo_gXC23q7Q', '22BOHMokEHyXf9LA8BARGg', 'nggKtoEk7I3N5_-NHbaTNg', 'Y_-jPp4HSI5Wf_GtYyn_jg', 'lFzD9HEYTS_c9nyNgTJHbg', 'c22KV-Ao3uMRMRRRWt3DGg', 'QM-6Q6LOmKAj1EhLlVZ7SA', '0VMkO2ox912FtPuSXnTd8g', '_Eq8EgtwLGiMFc7VJdb-YQ', 'U1-E4459q_nX0qqbc_n-JQ', '4KdsnwKN_pIC1RjApHX4Tg', 'NKvvcvtlSd5Hu81foZI2-w', 'qnpLDRFqzNVZmT8_CfkekA']\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"retrieved_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd65fd-967d-45cc-a166-ef5dfb2cb137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92babc1-61ce-4bc7-930b-a68f05efa4c0",
   "metadata": {},
   "source": [
    "python mapillary_sls/evaluate.py --prediction \"predictions.txt\" --msls-root \"msls/\" --cities \"cph,sf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c9aa15a8-5e79-455c-8972-86221c64191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#     results+=\" \"+ df.iloc[i][\"query_id\"] + \" \" +  \" \".join([str(i) for i in eval(df.iloc[i][\"re_ranked_ids\"])[:4]])\n",
    "#     results+=\"\\n\"\n",
    "\n",
    "\n",
    "with open('FIR/predictions.txt', 'w') as f:\n",
    "    for i in range(df.shape[0]):\n",
    "        results=df.iloc[i][\"query_id\"] + \" \" +  \" \".join([str(i) for i in eval(df.iloc[i][\"retrieved_ids\"])]) +\"\\n\"\n",
    "        f.write(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e5067-f7d9-4d8e-ab9a-be9c8ade9608",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b3dfe-27ea-49c7-b02c-10ec2a5aedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0][\"query_id\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed0901-0eed-4482-909a-5d09ea6909ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "'sss'.lstrip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1132f17e-7a83-41f5-96f5-27730608a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(index,df,top_k):\n",
    "    index = index\n",
    "    top_k = top_k\n",
    "    CPH_LEN = 6595\n",
    "    SF_LEN = 4525\n",
    "\n",
    "\n",
    "    with open(os.path.join(DATASET_VAL_CPH, \"query.json\"), \"r\") as f:\n",
    "        # load the query json file\n",
    "        query_cph = json.load(f)['im_paths']\n",
    "        # cph length\n",
    "        cph_len = len(query_cph)\n",
    "\n",
    "    # read the query json file for sf\n",
    "    with open(os.path.join(DATASET_VAL_SF, \"query.json\"), \"r\") as f:\n",
    "        # load the query json file\n",
    "        query_sf = json.load(f)['im_paths']\n",
    "        # sf length\n",
    "        sf_len = len(query_sf)\n",
    "\n",
    "    with open(os.path.join(DATASET_VAL_CPH, \"database.json\"), \"r\") as f:\n",
    "    # load the database json file\n",
    "        database_cph = json.load(f)['im_paths']\n",
    "        # cph length\n",
    "        cph_len = len(query_cph)\n",
    "    with open(os.path.join(DATASET_VAL_SF, \"database.json\"), \"r\") as f:\n",
    "    # load the database json file\n",
    "        database_sf = json.load(f)['im_paths']\n",
    "        # cph length\n",
    "        sf_len = len(database_sf)\n",
    "\n",
    "\n",
    "    files = []\n",
    "    query = DATASET_ROOT + \"/\" + query_cph[index] if index<=CPH_LEN else DATASET_ROOT + \"/\" + query_sf[abs(index-cph_len)]\n",
    "\n",
    "\n",
    "    for k in range(top_k):\n",
    "\n",
    "        for ranked_indices in eval(df.loc[index,\"re_ranked\"]):\n",
    "            if index<=CPH_LEN:\n",
    "                files.append(DATASET_ROOT + \"/\" +  database_cph[ranked_indices])\n",
    "            else:\n",
    "                files.append(DATASET_ROOT + \"/\" + database_sf[ranked_indices])\n",
    "            # else:\n",
    "\n",
    "    files_retrieved_indices = []\n",
    "    # retrieved_indices = eval(df.iloc[index,\"retrieved_indices\"])\n",
    "\n",
    "    # print(retrieved\n",
    "\n",
    "    for k in range(top_k):\n",
    "        for retrieved_indices in eval(df.loc[index,\"retrieved_indicies\"]):\n",
    "            # print(retrieved_indices)\n",
    "            if index<=CPH_LEN:\n",
    "                files_retrieved_indices.append(DATASET_ROOT + \"/\" +  database_cph[retrieved_indices])\n",
    "            else:\n",
    "                files_retrieved_indices.append(DATASET_ROOT + \"/\" + database_sf[retrieved_indices])\n",
    "\n",
    "\n",
    "    fig,axs = plt.subplots(1,top_k+1,figsize=(20, 20))\n",
    "\n",
    "\n",
    "    for index,ax in enumerate(axs):\n",
    "        if index==0: \n",
    "            image = plt.imread(query)\n",
    "            ax.imshow(image)\n",
    "            ax.title.set_text(f'Query')\n",
    "        else:\n",
    "            image = plt.imread(files[index-1])\n",
    "            ax.imshow(image)\n",
    "\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    fig,new_axs = plt.subplots(1,top_k+1,figsize=(20, 20))\n",
    "\n",
    "\n",
    "    for index,ax in enumerate(new_axs):\n",
    "        image = plt.imread(files_retrieved_indices[index])\n",
    "        ax.imshow(image)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()\n",
    "    print(\"#########\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd90d89-96ab-45c5-84de-1525c352c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(20):\n",
    "index = [0,100,200,1000,3200,500,400,0,10]\n",
    "for i in index:\n",
    "    plot_image(i,df,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993ac75-c5aa-469a-b8de-d2308abb9720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapillary_sls.datasets.msls import MSLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba520c2-a879-43c7-93e3-256e41c88158",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MSLS(DATASET_ROOT, cities = \"\", mode = 'val', posDistThr = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f8c37-f11b-4401-8d53-1c87a0e5e200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apfir",
   "language": "python",
   "name": "apfir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
