{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5be9a3f-37f4-4ecd-a606-8b77e30e1695",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>To re-rank</h3>\n",
    "\n",
    "- Function takes in a dictionary containing the key\n",
    "- \"features\" and \"configuration\"\n",
    "\n",
    "- \"features\" dictionary should contain all the path of map and query of both the features with this as the keys \n",
    "- \"configuration\" dictionary should contain all the required variables to run the experiment such as the fusion function, similarity measure function, cph_len, sf_len\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8f0b692-876d-491b-afca-6f8c47b3b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8d9e1-b4e5-4e86-b6ae-75fbe44166f8",
   "metadata": {},
   "source": [
    "<h3>Fusion Methods</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6239d534-f441-4d6d-b2cd-aba02105c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthogonal_fusion(global_matrix,local_matrix):\n",
    "    global_norm = torch.norm(global_matrix,p=2,dim=1)\n",
    "    projection = torch.mm(global_matrix,local_matrix.T)\n",
    "    projection = projection/(global_norm*global_norm)\n",
    "    orthogonal_comp = local_matrix-projection\n",
    "    fusion = torch.cat([global_matrix,orthogonal_comp],dim=1)\n",
    "    # global_feat.expand(orthogonal_comp.size()), orthogonal_comp\n",
    "    return fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80de81-cadb-456b-8bfd-c8fd79f3b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(global_features,local_features):\n",
    "    \"\"\"when you apply just the sequeeze() it removes all the ones\n",
    "    #so (1,2048,1,1) after squeezing -> (2048), adding that extra dimension on the zero \n",
    "    #axis :- unsqueeze(0) (1,2048)\"\"\"\n",
    "    \n",
    "\n",
    "    if global_features.shape[0]==1:\n",
    "        \n",
    "        x = np.multiply(local_features,global_features).squeeze().unsqueeze(0)\n",
    "\n",
    "    else: #if we have batch size!=1, then we dont have to unsqueeze because it wont squeeze the batch size               \n",
    "        #hardaman product\n",
    "        x = np.multiply(local_features,global_features).squeeze()\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db8f00-8924-4d5b-8610-d58068daafee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b978a-4620-4b2b-a343-5d7f6f47d56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a5a4252-1e2d-4aae-9ff7-c1642014a4d5",
   "metadata": {},
   "source": [
    "<h3>Helpers for Re-ranking</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f48450e7-b6ce-49a4-ba32-4e6b1dd75252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the features given feature dictionary and returns back the path\n",
    "\n",
    "def load_files(features):\n",
    "    local_cph_query = torch.from_numpy(np.load(features[\"cph\"][\"local_query\"]))\n",
    "    global_cph_query =  torch.from_numpy(np.load(features[\"cph\"][\"global_query\"]))\n",
    "\n",
    "    local_sf_query =  torch.from_numpy(np.load(features[\"sf\"][\"local_query\"]))\n",
    "    global_sf_query =  torch.from_numpy(np.load(features[\"sf\"][\"global_query\"]))\n",
    "\n",
    "    local_cph_database =  torch.from_numpy(np.load(features[\"cph\"][\"local_database\"]))\n",
    "    global_cph_database =  torch.from_numpy(np.load(features[\"cph\"][\"global_database\"]))\n",
    "\n",
    "    local_sf_database =  torch.from_numpy(np.load(features[\"sf\"][\"local_database\"]))\n",
    "    global_sf_database =  torch.from_numpy(np.load(features[\"sf\"][\"global_database\"]))\n",
    "    \n",
    "    return local_cph_query,global_cph_query,\\\n",
    "            local_sf_query,global_sf_query,\\\n",
    "            local_cph_database,global_cph_database,\\\n",
    "            local_sf_database,global_sf_database\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "931618d8-2a9c-45cf-869b-12c5007534f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(path,filename,df):\n",
    "    path = os.path.join(path,filename)\n",
    "    with open(path, 'w') as f:\n",
    "        for i in range(df.shape[0]):\n",
    "            results=df.iloc[i][\"query_id\"] + \" \" +  \" \".join([str(i) for i in eval(df.iloc[i][\"re_ranked_ids\"])]) +\"\\n\"\n",
    "            f.write(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049abaf6-3165-41bd-8646-7b2b56bf5830",
   "metadata": {},
   "source": [
    "<h3>Re-ranking</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4185e3a0-5aa0-43c5-8bb5-b4b90923281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rank(features,configuration):\n",
    "    \n",
    "    #Load experimental configuration\n",
    "    \n",
    "    CPH_LEN = configuration[\"cph_len\"]\n",
    "    SF_LEN = configuration[\"sf_len\"]\n",
    "    fusion = configuration[\"fusion\"]\n",
    "    df = pd.read_csv(configuration[\"df\"])\n",
    "    similarity_measure = configuration[\"similarity_measure\"]\n",
    "    \n",
    "    #Unpacking the features\n",
    "    \n",
    "    local_features_cph_query,global_features_cph_query,\\\n",
    "    local_features_sf_query,global_features_sf_query,\\\n",
    "    local_features_cph_database,global_features_cph_database,\\\n",
    "    local_features_sf_database,global_features_sf_database = load_files(features)\n",
    "    \n",
    "    for row in range(df.shape[0]):    \n",
    "\n",
    "        if row<CPH_LEN:\n",
    "            #unsqueezing because when we access it we result in ([2048]), to make it ([1,2048])\n",
    "            #same for global\n",
    "            local_feature_query = local_features_cph_query[row].unsqueeze(0)\n",
    "            global_feature_query = global_features_cph_query[row].unsqueeze(0)\n",
    "            \n",
    "            #applying the fusion (1,4096)\n",
    "            query_fusion = fusion(global_feature_query,local_feature_query)\n",
    "\n",
    "            #eval basically converts to the required datatype given the string format\n",
    "\n",
    "            retrieved_indices = eval(df.iloc[row][\"retrieved_indicies\"])\n",
    "            retrieved_ids =  eval(df.iloc[row][\"retrieved_ids\"])\n",
    "            \n",
    "            idx_id = {i:j for i,j in zip(retrieved_indices,retrieved_ids)}\n",
    "     \n",
    "            database_feature_list = None\n",
    "        \n",
    "            #fetching all the features first and concatenating them\n",
    "            for database_id in retrieved_indices:\n",
    "                #same reason as above(to why we unsqueezing)\n",
    "                global_feature_database = global_features_cph_database[database_id].unsqueeze(0)\n",
    "                \n",
    "                local_feature_database = local_features_cph_database[database_id].unsqueeze(0)\n",
    "                #(1,4096)\n",
    "                combined_features = fusion(global_feature_database,local_feature_database)\n",
    "\n",
    "                if database_feature_list is None:\n",
    "                    database_feature_list = combined_features\n",
    "                else:\n",
    "                    database_feature_list = torch.cat([database_feature_list,combined_features])\n",
    "                    \n",
    "            #so now we result the size of database_feature_list as -> (top_k,4096)\n",
    "            #computing the similarity so we get (1,top_k) size. 1 because, 1 query image passed in\n",
    "            similarity =  similarity_measure(query_fusion,database_feature_list)\n",
    "            \n",
    "            #getting the indices of the most similar and mapping to the retrieved list\n",
    "            ranked_indices = [retrieved_indices[i] for i in np.argsort(similarity)[0]]\n",
    "\n",
    "            retrieved_file_names = [idx_id[i] for i in ranked_indices]\n",
    "\n",
    "            df.loc[row,\"re_ranked\"] = str(ranked_indices)\n",
    "            df.loc[row,\"re_ranked_ids\"] = str(retrieved_file_names)\n",
    "\n",
    "        else: #For SF\n",
    "            \n",
    "            row = abs(row-CPH_LEN) \n",
    "            \n",
    "            local_feature_query = local_features_sf_query[row].unsqueeze(0)\n",
    "            global_feature_query = global_features_sf_query[row].unsqueeze(0)\n",
    "\n",
    "            query_fusion = fusion(global_feature_query,local_feature_query)\n",
    "        \n",
    "            \n",
    "            retrieved_indices = eval(df.iloc[CPH_LEN+row][\"retrieved_indicies\"])\n",
    "            \n",
    "            retrieved_ids =  eval(df.iloc[CPH_LEN+row][\"retrieved_ids\"])\n",
    "            \n",
    "            idx_id = {i:j for i,j in zip(retrieved_indices,retrieved_ids)}\n",
    "\n",
    "            \n",
    "            database_feature_list = None\n",
    "            \n",
    "            for database_id in retrieved_indices:\n",
    "          \n",
    "                global_feature_database = global_features_sf_database[database_id].unsqueeze(0)\n",
    "                \n",
    "                local_feature_database = local_features_sf_database[database_id].unsqueeze(0)\n",
    "                combined_features = fusion(global_feature_database,local_feature_database)\n",
    "\n",
    "\n",
    "                if database_feature_list is None:\n",
    "                    database_feature_list = combined_features\n",
    "                else:\n",
    "                    database_feature_list = torch.cat([database_feature_list,combined_features])\n",
    "            \n",
    "            similarity = similarity_measure(query_fusion,database_feature_list)\n",
    "            \n",
    "            ranked_indices = [retrieved_indices[i] for i in np.argsort(similarity)[0]]\n",
    "            \n",
    "            retrieved_file_names = [idx_id[i] for i in ranked_indices]\n",
    "            \n",
    "            df.loc[CPH_LEN+row,\"re_ranked\"] = str(ranked_indices)\n",
    "            df.loc[CPH_LEN+row,\"re_ranked_ids\"] = str(retrieved_file_names)\n",
    "            \n",
    "    #writing the results\n",
    "    \n",
    "    write(configuration[\"results_path\"],configuration[\"results_filename\"],df)\n",
    "\n",
    "    if configuration[\"return_df\"]==True:\n",
    "        return df\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396dc340-35d8-49f1-b04a-64eca221a0a1",
   "metadata": {},
   "source": [
    "<h3>Sample on how to run</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54f78966-91f2-4ce1-88c9-bbced38c4d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"FIR\"\n",
    "DIR_ADVANCED_IR = os.path.join(DATA_ROOT, \"advanced_ir\") #i added the local features into a folder 'weights' in advanced_ir\n",
    "DATASET_ROOT = os.path.join(DATA_ROOT, \"msls\")\n",
    "DATASET_TEST = os.path.join(DATASET_ROOT, \"test\")\n",
    "DATASET_VAL = os.path.join(DATASET_ROOT, \"train_val\")\n",
    "DATASET_VAL_SF = os.path.join(DATASET_VAL, \"sf\")\n",
    "DATASET_VAL_CPH = os.path.join(DATASET_VAL, \"cph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d8966fe8-4ec2-4cca-bf3a-2df6669ab3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    \"cph\": \n",
    "        {\n",
    "            \"local_query\" :os.path.join(DIR_ADVANCED_IR,\"weights/MSLS_resnext_GCL_multi_attrous_attention_map_cph_local_queryfeats.npy\") ,\n",
    "            \"global_query\" : os.path.join(DATA_ROOT,\"results/MSLS/val/MSLS_resnext_GeM_480_GCL_cph_queryfeats.npy\"),\n",
    "            \"local_database\" : os.path.join(DIR_ADVANCED_IR,\"weights/MSLS_resnext_GCL_multi_attrous_attention_map_cph_local_mapfeats.npy\"),\n",
    "            \"global_database\" : os.path.join(DATA_ROOT,\"results/MSLS/val/MSLS_resnext_GeM_480_GCL_cph_mapfeats.npy\") \n",
    "        },\n",
    "\n",
    "    \"sf\":\n",
    "        {\n",
    "        \"local_query\" : os.path.join(DIR_ADVANCED_IR,\"weights/MSLS_resnext_GCL_multi_attrous_attention_map_sf_local_queryfeats.npy\"),\n",
    "        \"global_query\" : os.path.join(DATA_ROOT,\"results/MSLS/val/MSLS_resnext_GeM_480_GCL_sf_queryfeats.npy\"), \n",
    "        \"local_database\" : os.path.join(DIR_ADVANCED_IR,\"weights/MSLS_resnext_GCL_multi_attrous_attention_map_sf_local_mapfeats.npy\"), \n",
    "        \"global_database\" : os.path.join(DATA_ROOT,\"results/MSLS/val/MSLS_resnext_GeM_480_GCL_sf_mapfeats.npy\")\n",
    "\n",
    "        }\n",
    "}\n",
    "\n",
    "configuration = {\n",
    "    \"similarity_measure\" : manhattan_distances, #similarity function\n",
    "    \"fusion\" : orthogonal_fusion, #fusion function\n",
    "    \"df\" :   \"FIR/advanced_ir/data.csv\",\n",
    "    \"cph_len\" : 6595,\n",
    "    \"sf_len\" : 4525,\n",
    "    \"results_path\": \"FIR/advanced_ir\",\n",
    "    \"results_filename\": \"predictions.txt\",\n",
    "    \"return_df\" : True\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77d7d1ee-2be8-41f3-aef7-d471c38b4e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query_id</th>\n",
       "      <th>retrieved_ids</th>\n",
       "      <th>retrieved_indicies</th>\n",
       "      <th>re_ranked</th>\n",
       "      <th>re_ranked_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>x3vA7Bk0HNI6rGkDpDZQUQ</td>\n",
       "      <td>['X9V1oGRaAEFjq5jufrklTQ', 'E7gcrCyitkguCnMzoE...</td>\n",
       "      <td>[3, 5130, 5131, 0, 7912, 5132, 8812, 9186, 1, ...</td>\n",
       "      <td>[3, 0, 5130, 5131, 8812, 1, 7912, 4505, 5132, ...</td>\n",
       "      <td>['X9V1oGRaAEFjq5jufrklTQ', 'm6_LAhWivjGN4O1fkW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>U9Vj0IV4q1psciXpj51F_w</td>\n",
       "      <td>['X9V1oGRaAEFjq5jufrklTQ', '22BOHMokEHyXf9LA8B...</td>\n",
       "      <td>[3, 4504, 1, 1815, 9186, 0, 2, 9181, 5131, 513...</td>\n",
       "      <td>[1, 3, 4504, 9183, 9181, 9182, 9184, 2, 1815, ...</td>\n",
       "      <td>['HU9GEfLAB9pm5RmjW4MLhg', 'X9V1oGRaAEFjq5jufr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Eh1NwQjH4jbKcWqVJ4ZsJg</td>\n",
       "      <td>['X9V1oGRaAEFjq5jufrklTQ', '_Eq8EgtwLGiMFc7VJd...</td>\n",
       "      <td>[3, 4, 2, 1815, 7604, 1, 0, 8810, 5, 9186, 6, ...</td>\n",
       "      <td>[3, 2, 4, 1, 0, 8810, 5, 6, 7604, 8809, 5133, ...</td>\n",
       "      <td>['X9V1oGRaAEFjq5jufrklTQ', 'qhZA-uC4KY1F38C_Hb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1RKCGBAWsZbi5dj3vR2mlw</td>\n",
       "      <td>['_Eq8EgtwLGiMFc7VJdb-YQ', 'X9V1oGRaAEFjq5jufr...</td>\n",
       "      <td>[4, 3, 5, 6, 0, 8815, 9186, 9181, 8798, 1, 513...</td>\n",
       "      <td>[4, 3, 5, 6, 9181, 0, 1, 12219, 8815, 8810, 91...</td>\n",
       "      <td>['_Eq8EgtwLGiMFc7VJdb-YQ', 'X9V1oGRaAEFjq5jufr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LdiYwYkqgUfc1IYDu5ov9A</td>\n",
       "      <td>['Z4MR4AHQufgsCwiBiqQ23A', 'eQ-8kVNfMZiexVcu_V...</td>\n",
       "      <td>[5, 6, 4, 8815, 5133, 7049, 5125, 8816, 8811, ...</td>\n",
       "      <td>[5, 6, 4, 3, 5133, 12219, 8816, 8815, 34, 1192...</td>\n",
       "      <td>['Z4MR4AHQufgsCwiBiqQ23A', 'eQ-8kVNfMZiexVcu_V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                query_id  \\\n",
       "0           0  x3vA7Bk0HNI6rGkDpDZQUQ   \n",
       "1           1  U9Vj0IV4q1psciXpj51F_w   \n",
       "2           2  Eh1NwQjH4jbKcWqVJ4ZsJg   \n",
       "3           3  1RKCGBAWsZbi5dj3vR2mlw   \n",
       "4           4  LdiYwYkqgUfc1IYDu5ov9A   \n",
       "\n",
       "                                       retrieved_ids  \\\n",
       "0  ['X9V1oGRaAEFjq5jufrklTQ', 'E7gcrCyitkguCnMzoE...   \n",
       "1  ['X9V1oGRaAEFjq5jufrklTQ', '22BOHMokEHyXf9LA8B...   \n",
       "2  ['X9V1oGRaAEFjq5jufrklTQ', '_Eq8EgtwLGiMFc7VJd...   \n",
       "3  ['_Eq8EgtwLGiMFc7VJdb-YQ', 'X9V1oGRaAEFjq5jufr...   \n",
       "4  ['Z4MR4AHQufgsCwiBiqQ23A', 'eQ-8kVNfMZiexVcu_V...   \n",
       "\n",
       "                                  retrieved_indicies  \\\n",
       "0  [3, 5130, 5131, 0, 7912, 5132, 8812, 9186, 1, ...   \n",
       "1  [3, 4504, 1, 1815, 9186, 0, 2, 9181, 5131, 513...   \n",
       "2  [3, 4, 2, 1815, 7604, 1, 0, 8810, 5, 9186, 6, ...   \n",
       "3  [4, 3, 5, 6, 0, 8815, 9186, 9181, 8798, 1, 513...   \n",
       "4  [5, 6, 4, 8815, 5133, 7049, 5125, 8816, 8811, ...   \n",
       "\n",
       "                                           re_ranked  \\\n",
       "0  [3, 0, 5130, 5131, 8812, 1, 7912, 4505, 5132, ...   \n",
       "1  [1, 3, 4504, 9183, 9181, 9182, 9184, 2, 1815, ...   \n",
       "2  [3, 2, 4, 1, 0, 8810, 5, 6, 7604, 8809, 5133, ...   \n",
       "3  [4, 3, 5, 6, 9181, 0, 1, 12219, 8815, 8810, 91...   \n",
       "4  [5, 6, 4, 3, 5133, 12219, 8816, 8815, 34, 1192...   \n",
       "\n",
       "                                       re_ranked_ids  \n",
       "0  ['X9V1oGRaAEFjq5jufrklTQ', 'm6_LAhWivjGN4O1fkW...  \n",
       "1  ['HU9GEfLAB9pm5RmjW4MLhg', 'X9V1oGRaAEFjq5jufr...  \n",
       "2  ['X9V1oGRaAEFjq5jufrklTQ', 'qhZA-uC4KY1F38C_Hb...  \n",
       "3  ['_Eq8EgtwLGiMFc7VJdb-YQ', 'X9V1oGRaAEFjq5jufr...  \n",
       "4  ['Z4MR4AHQufgsCwiBiqQ23A', 'eQ-8kVNfMZiexVcu_V...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank(features,configuration).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f47bbb-ad7b-4afa-9a95-9aff7a2b7a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e235d2-2850-4054-8860-c63c09cb4369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d74f6d-6e13-4c29-b38a-3f231b247ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apfir",
   "language": "python",
   "name": "apfir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
