{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2c9cf8-7f2c-4913-87ba-918f5788e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/apfir/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from generalized_contrastive_loss.datasets import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b55db1-2946-4ada-9c4c-a8f4a8425e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6, requires_grad=False):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p, requires_grad=requires_grad)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "class BaseNet(nn.Module):\n",
    "    def __init__(self, backbone, global_pool=None, poolkernel=7, norm=None, p=3, num_clusters=64):\n",
    "        super(BaseNet, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "                n=param.size()[0]\n",
    "        self.num_features=n\n",
    "        self.pretrained_cfg = {}\n",
    "        self.num_classes=0\n",
    "        if global_pool == \"max\":\n",
    "            self.pool = nn.AdaptiveMaxPool2d(output_size=(1, 1))\n",
    "        elif global_pool == \"avg\":\n",
    "            self.pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        elif global_pool == \"GeM\":\n",
    "            self.pool=GeM(p=p)\n",
    "        else:\n",
    "            self.pool = None\n",
    "        self.norm=norm\n",
    "\n",
    "    # This function returns both local and global features\n",
    "    def forward(self, x0):\n",
    "\n",
    "        # conv1\n",
    "        x0 = self.backbone[0](x0)\n",
    "        # bn1\n",
    "        x0 = self.backbone[1](x0)\n",
    "        # relu\n",
    "        x0 = self.backbone[2](x0)\n",
    "        # max0pool\n",
    "        x0 = self.backbone[3](x0)\n",
    "        # layer1\n",
    "        x0 = self.backbone[4](x0)\n",
    "        # layer2\n",
    "        x0 = self.backbone[5](x0)\n",
    "        # layer3\n",
    "        local_features = self.backbone[6](x0)\n",
    "        # print(f\"local feature size {local_features.size()}\")\n",
    "        \n",
    "        # layer4. This is equivalent to do out = self.backbone.forward(x0)    \n",
    "        global_features = self.backbone[7](local_features)\n",
    "        # print(f\"global feature size before squeezing {global_features.size()}\")\n",
    "        \n",
    "        # Apply GeM pooling on the features from layer 4 \n",
    "        global_features = self.pool.forward(global_features).squeeze(-1).squeeze(-1)\n",
    "        # print(f\"global feature size after squeezing and pooling {global_features.size()}\")\n",
    "        \n",
    "        # Apply GeM pooling on the local features \n",
    "        local_features = self.pool.forward(local_features).squeeze(-1).squeeze(-1)\n",
    "        # print(f\"local feature size after pooling {local_features.size()}\")\n",
    "        if self.norm == \"L2\":\n",
    "            global_features=nn.functional.normalize(global_features)\n",
    "        return local_features, global_features\n",
    "\n",
    "\n",
    "class SiameseNet(BaseNet):\n",
    "    def __init__(self, backbone, global_pool=None, poolkernel=7,norm=None, p=3,num_clusters=64):\n",
    "        super(SiameseNet, self).__init__(backbone, global_pool, poolkernel, norm=norm, p=p,num_clusters=num_clusters)\n",
    "\n",
    "    def forward(self, x0, x1):\n",
    "        out0 = super(SiameseNet, self).forward(x0)\n",
    "        out1 = super(SiameseNet, self).forward(x1)\n",
    "        return out0, out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259d737-26ed-4044-ba92-40cdc1864a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, root_dir, idx_file, gt_file, image_t, batch_size):\n",
    "    # Create dataset\n",
    "    if dataset==\"test\":\n",
    "        ds = TestDataSet(root_dir, idx_file, transform=image_t)\n",
    "        return DataLoader(ds, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "    if dataset == \"soft_siamese\":\n",
    "        ds = SiameseDataSet(root_dir, idx_file, gt_file, ds_key=\"fov\", transform=image_t)\n",
    "    elif dataset == \"binary_siamese\":\n",
    "        ds = SiameseDataSet(root_dir, idx_file, gt_file, ds_key=\"sim\", transform=image_t)\n",
    "    return DataLoader(ds, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "\n",
    "def get_backbone(name):\n",
    "    if name == \"resnet18\":\n",
    "        backbone = models.resnet18(pretrained=True)\n",
    "    elif name == \"resnet34\":\n",
    "        backbone = models.resnet34(pretrained=True)\n",
    "    elif name == \"resnet152\":\n",
    "        backbone = models.resnet152(pretrained=True)\n",
    "    elif name == \"resnet50\":\n",
    "        backbone = models.resnet50(pretrained=True)\n",
    "    if name == \"densenet161\":\n",
    "        backbone = models.densenet161(pretrained=True).features\n",
    "        output_dim=2208\n",
    "    elif name == \"densenet121\":\n",
    "        backbone = models.densenet121(pretrained=True).features\n",
    "        output_dim=2208\n",
    "    elif name == \"vgg16\":\n",
    "        backbone = models.vgg16(pretrained=True).features\n",
    "        output_dim=512\n",
    "    elif name == \"resnext\":\n",
    "        backbone = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\n",
    "        # Supposed to be ['conv1', 'bn1', 'relu', 'maxpool', 'layer1', 'layer2', 'layer3', 'layer4', 'avgpool', 'fc']\n",
    "        print(f\" the layers of the resnext101_32x8d_wsl are: {backbone._modules.keys()}\")\n",
    "    if \"resne\" in name:\n",
    "        backbone = torch.nn.Sequential(*(list(backbone.children())[:-2]))\n",
    "        output_dim = 2048\n",
    "        print(f\" the layers of the resnext101_32x8d_wsl are after removing the last two layers (avgpool and fc): {backbone._modules.keys()}\")\n",
    "    return backbone, output_dim\n",
    "\n",
    "\n",
    "def create_model(name, pool, last_layer=None, norm=None, p_gem=3, num_clusters=64, mode=\"siamese\"):\n",
    "    backbone, output_dim = get_backbone(name)\n",
    "    layers = len(list(backbone.children()))\n",
    "    print(f\"Number of layers: {layers}\")\n",
    "\n",
    "    if last_layer is None:\n",
    "        last_layer = layers\n",
    "    elif \"densenet\" in name:\n",
    "        last_layer=last_layer*2\n",
    "    elif \"vgg\" in name:\n",
    "    \tlast_layer=last_layer*8-2\n",
    "    aux = 0\n",
    "    for c in backbone.children():\n",
    "\n",
    "        if aux < layers - last_layer:\n",
    "            print(aux, c._get_name(), \"IS FROZEN\")\n",
    "            for p in c.parameters():\n",
    "                p.requires_grad = False\n",
    "        else:\n",
    "            print(aux, c._get_name(), \"IS TRAINED\")\n",
    "        aux += 1\n",
    "    if mode==\"siamese\":\n",
    "        return SiameseNet(backbone, pool, norm=norm, p=p_gem, num_clusters=num_clusters)\n",
    "    elif mode==\"triplet\":\n",
    "        return TripletNet(backbone, pool, norm=norm, p=p_gem, num_clusters=num_clusters)\n",
    "    else:\n",
    "        return BaseNet(backbone, pool, norm=norm, p=p_gem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3813",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbf36edf16826f338fcddf9817feee204e82a9d331b7cc35297b5ee4d265a83d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
