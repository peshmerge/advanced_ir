{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5be9a3f-37f4-4ecd-a606-8b77e30e1695",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Re-rank\n",
    "\n",
    "- Function takes in a dictionary containing the key\n",
    "- \"features\" and \"configuration\"\n",
    "\n",
    "- \"features\" dictionary should contain all the path of map and query of both the features with this as the keys \n",
    "- \"configuration\" dictionary should contain all the required variables to run the experiment such as the fusion function, similarity measure function, cph_len, sf_len\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8f0b692-876d-491b-afca-6f8c47b3b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570623c5-e591-49e2-b9ce-ba97800c4801",
   "metadata": {},
   "source": [
    "### Generate Dataframe\n",
    "Generate a dataframe for all indicies from retrieved results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af02c1bb-d500-4f8e-9c7f-3ad0d5537a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pred_indicies(prediction_path, validation_path, cities, display_df = False):\n",
    "    # Read the prediction text file\n",
    "    df = pd.read_fwf(prediction_path, header=None)\n",
    "    # Combine all but first column as a list of predictions\n",
    "    df['combined'] = df.drop(0, axis=1).values.tolist()\n",
    "    # Replace the dataframe with the first col (query image id) and combined list\n",
    "    df = df[[0, 'combined']]\n",
    "    # Name the columns appropriately\n",
    "    df.columns = ['query_id', 'retrieved_ids']\n",
    "    # create a new column for lists in the dataframe\n",
    "    df['retrieved_indicies'] = [[] for x in range(len(df))]\n",
    "\n",
    "    curr_idx = 0  # keeps track of the beginning idx in the pandas dataframe\n",
    "    end_idx = 0  # ending idx in the dataframe\n",
    "    city_lens = {city: 0 for city in cities}\n",
    "    for city in cities:\n",
    "        city_data = os.path.join(validation_path, city)\n",
    "        # read the query json file for cph\n",
    "        with open(os.path.join(city_data, \"query.json\"), \"r\") as f:\n",
    "            # load the query json file\n",
    "            query_data = json.load(f)['im_paths']\n",
    "            # query data length\n",
    "            end_idx = len(query_data)\n",
    "            city_lens[city] = end_idx\n",
    "        # load the database file and index it on a map for fast lookup\n",
    "        with open(os.path.join(city_data, \"database.json\"), \"r\") as f:\n",
    "            database_data = json.load(f)\n",
    "        # one time pass to load it as a dictionary\n",
    "        query_image_ids = {x.replace('.', '/').split('/')[4]: i for i, x in enumerate(database_data['im_paths'])}\n",
    "\n",
    "        # for each row apply the fuction to retrieve the ids\n",
    "        df.loc[curr_idx:curr_idx+end_idx-1, 'retrieved_indicies'] = df.loc[curr_idx:curr_idx+end_idx-1].apply(lambda x: [query_image_ids[i] for i in x['retrieved_ids']], axis=1)\n",
    "        curr_idx += end_idx\n",
    "\n",
    "    # If needed, print the dataframe\n",
    "    if display_df:\n",
    "        display(df)\n",
    "\n",
    "    return df, city_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a4252-1e2d-4aae-9ff7-c1642014a4d5",
   "metadata": {},
   "source": [
    "<h3>Helpers for Re-ranking</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "931618d8-2a9c-45cf-869b-12c5007534f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(path, filename, df):\n",
    "    path = os.path.join(path, filename)\n",
    "    with open(path, 'w') as f:\n",
    "        for i in range(df.shape[0]):\n",
    "            results = df.loc[i, \"query_id\"] + \" \" + df.loc[i, \"re_ranked_ids\"] +\"\\n\"\n",
    "            f.write(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049abaf6-3165-41bd-8646-7b2b56bf5830",
   "metadata": {},
   "source": [
    "<h3>Re-ranking</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4185e3a0-5aa0-43c5-8bb5-b4b90923281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(configuration):\n",
    "    # Load the configuration and data\n",
    "    retrieved_df, data_lengths = generate_pred_indicies(\n",
    "        configuration[\"prediction_path\"],\n",
    "        configuration[\"data_path\"],\n",
    "        configuration[\"cities\"],\n",
    "        False\n",
    "    )\n",
    "    similarity_measure = configuration[\"similarity_measure\"]\n",
    "    fusion_method = configuration[\"fusion_method\"]\n",
    "    features_path = configuration[\"features_path\"]\n",
    "    local_feat_format = configuration[\"local_feat_format\"]\n",
    "    global_feat_format = configuration[\"global_feat_format\"]\n",
    "    fusion = configuration[\"fusion\"]\n",
    "\n",
    "    curr_idx = 0\n",
    "    for city in configuration[\"cities\"]:\n",
    "        # Load local features\n",
    "        query_local = torch.Tensor(\n",
    "            np.load(os.path.join(features_path, local_feat_format.format(city=city, db=\"query\")))\n",
    "        )\n",
    "        map_local = torch.Tensor(\n",
    "            np.load(os.path.join(features_path, local_feat_format.format(city=city, db=\"map\")))\n",
    "        )\n",
    "\n",
    "        # Get end lengths\n",
    "        end_idx = data_lengths[city]\n",
    "\n",
    "        # If fusion needs to be done...\n",
    "        if fusion:\n",
    "            # Load global features\n",
    "            query_global = torch.Tensor(\n",
    "                np.load(os.path.join(features_path, global_feat_format.format(city=city, db=\"query\")))\n",
    "            )\n",
    "            map_global = torch.Tensor(\n",
    "                np.load(os.path.join(features_path, global_feat_format.format(city=city, db=\"map\")))\n",
    "            )\n",
    "            # Do fusion between local and global features\n",
    "            query_fusion = fusion_method.forward(query_local, query_global)\n",
    "            map_fusion = fusion_method.forward(map_local, map_global)\n",
    "        else:\n",
    "            # Otherwise, just keep without fusion for local only\n",
    "            query_fusion = query_local\n",
    "            map_fusion = map_local\n",
    "\n",
    "        # Retrieve the ids and indicies from dataframe\n",
    "        retrieved_indices = torch.tensor(retrieved_df.loc[curr_idx:curr_idx+end_idx-1][\"retrieved_indicies\"].tolist())\n",
    "        retrieved_ids = retrieved_df.loc[curr_idx:curr_idx+end_idx-1][\"retrieved_ids\"].tolist()\n",
    "\n",
    "        # Gather the features in the map features relating to those indicies\n",
    "        for idx in tqdm(range(retrieved_indices.shape[0]), desc=f\"Ranking for {city}\"):\n",
    "            # idx (one query image) -> (30, 4096)\n",
    "            database_feature_list = map_fusion.index_select(0, retrieved_indices[idx])\n",
    "            # (1, 4096) == (30, 4096) -> (1, 30)\n",
    "            row_similarity = similarity_measure(query_fusion[idx].unsqueeze(0), database_feature_list)\n",
    "            # (1, 30) -> sorted((1,30))[0] -> 30\n",
    "            ranked_indicies = torch.argsort(row_similarity)[0]\n",
    "            retrieved_df.loc[curr_idx+idx, \"re_ranked_ids\"] = \" \".join([retrieved_ids[idx][i] for i in ranked_indicies])\n",
    "\n",
    "        curr_idx += end_idx\n",
    "\n",
    "    # Writing the results to the file\n",
    "    print(f\"Writing the results to {os.path.join(configuration['features_path'], configuration['results_file_format'])}.\")\n",
    "    write(configuration[\"features_path\"], configuration[\"results_file_format\"], retrieved_df)\n",
    "\n",
    "    return retrieved_df, os.path.join(configuration[\"features_path\"], configuration[\"results_file_format\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apfir",
   "language": "python",
   "name": "apfir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
